{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "muslim-highlight",
   "metadata": {},
   "source": [
    "# Clarity metrics\n",
    "Included in this notebook:\n",
    "- Average sentence length (by number of words)\n",
    "- Average word length (by number of syllables)\n",
    "- Readability index Szigriszt-Pazos\n",
    "- Usage of common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "defensive-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from wordfreq import word_frequency, top_n_list, get_language_info # Documentation: https://github.com/LuminosoInsight/wordfreq/\n",
    "import textstat # Documentation: https://github.com/shivam5992/textstat\n",
    "from textstat import szigriszt_pazos\n",
    "textstat.set_lang('es')\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "certified-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load articles of authors\n",
    "data = pd.read_csv('../Data/Data_clean_csv/clean_dataframe.csv')\n",
    "\n",
    "with open('../Data/Data_clean_txt/Denisse Dresser.txt', 'r', encoding='utf8') as f:\n",
    "    dresser_content = f.read()\n",
    "    \n",
    "with open('../Data/Data_clean_txt/Enrique Krauze.txt', 'r', encoding='utf8') as f:\n",
    "    krauze_content = f.read()\n",
    "    \n",
    "with open('../Data/Data_clean_txt/John Ackerman.txt', 'r', encoding='utf8') as f:\n",
    "    ackerman_content = f.read()\n",
    "    \n",
    "with open('../Data/Data_clean_txt/Ricardo Raphael.txt', 'r', encoding='utf8') as f:\n",
    "    raphael_content = f.read()\n",
    "    \n",
    "with open('../Data/Data_clean_txt/Valeria Moy.txt', 'r', encoding='utf8') as f:\n",
    "    moy_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "talented-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty article\n",
    "data = data.drop(1216).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-norwegian",
   "metadata": {},
   "source": [
    "## Average sentence length (by number of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "three-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_cleaner(text):\n",
    "    \"\"\" Removes html expressions and line breaks\"\"\"\n",
    "    \n",
    "    text = re.sub(r'(\\n|\\r)', '', text)\n",
    "    \n",
    "    # Remove signature of Ricardo Raphael's articles\n",
    "    text = re.sub(r'@ricardomraphael', '', text)\n",
    "    \n",
    "    # Remove italics\n",
    "    text = re.sub(r'<i>', '', text)\n",
    "    text = re.sub(r'<\\\\i>', '', text)\n",
    "    \n",
    "    # Remove bold\n",
    "    text = re.sub(r'<b>', '', text)\n",
    "    text = re.sub(r'<\\\\b>', '', text)\n",
    "    \n",
    "    #Remove multiple spaces\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    text = re.sub(r'\\s,\\s', ', ', text)\n",
    "      \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "inside-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_words_per_sentence(text):\n",
    "    \"\"\"Returns average words per sentence of a text\"\"\"\n",
    "    \n",
    "    # Clean html expressions and line breaks\n",
    "    text = html_cleaner(text)\n",
    "    \n",
    "    #Split into sentences\n",
    "    sentence_regex = re.compile('[\\.|\\?\\s?|!]\\s')\n",
    "    sentences = sentence_regex.split(text)\n",
    "    \n",
    "    #Remove empty sentences\n",
    "    for sentence in sentences:\n",
    "        if not sentence:\n",
    "            sentences.remove(sentence)\n",
    "    \n",
    "    #Count words in each string\n",
    "    words_per_sentence = [len(re.findall(r'\\w+', sentence)) for sentence in sentences]\n",
    "        \n",
    "    #Get average words per sentence\n",
    "    avg_words_per_sentence = sum(words_per_sentence) / len(words_per_sentence)\n",
    "        \n",
    "    return avg_words_per_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-harris",
   "metadata": {},
   "source": [
    "## Average word length (by number of syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "golden-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_cleaner(text):\n",
    "    \"\"\"Removes all punctuation and special characters from a text\"\"\"\n",
    "    \n",
    "    text = re.sub(r'[^A-Za-z\\sáéíóúñ]+', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "pursuant-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_syllables_per_word(text):\n",
    "    \"\"\"Returns average syllables per word of a text\"\"\"\n",
    "    \n",
    "    # Clean html expressions, line breaks, and punctuation\n",
    "    text = html_cleaner(text)\n",
    "    text = punctuation_cleaner(text)\n",
    "    \n",
    "    #Remove initialisms and acronyms\n",
    "    text = re.sub(r'\\b[A-ZÑ]{2,}\\b', '', text)\n",
    "    \n",
    "    # Remove Roman numerals\n",
    "    text = re.sub(r'\\b[IVXL]+\\b', '', text)\n",
    "    \n",
    "    #Remove multiple spaces\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    text = re.sub(r'\\s,\\s', ', ', text)\n",
    "    text = re.sub(r'\\s+$', '', text)\n",
    "    \n",
    "    # Lowercase all words\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Calculate average number of syllables per word\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    syllables_per_word = [textstat.syllable_count(word) for word in words]\n",
    "    avg_syllables_per_word = sum(syllables_per_word) / len(words)\n",
    "    \n",
    "    return avg_syllables_per_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-kennedy",
   "metadata": {},
   "source": [
    "## Readability index Szigriszt-Pazos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-thanks",
   "metadata": {},
   "source": [
    "This index is a Spanish adaptation of the Flesch readability-ease test, which considers average words per sentence and average syllables per word.\n",
    "\n",
    "See https://legible.es/blog/perspicuidad-szigriszt-pazos/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-consent",
   "metadata": {},
   "source": [
    "| Score | Difficulty | Education level |\n",
    "| ----- | ---------- | --------------- |\n",
    "|0-15| Very hard|University graduates\n",
    "|16-35| Hard| University graduates\n",
    "|36-50| Somewhat hard| College\n",
    "|51-65| Normal| 13 to 15-year-old students\n",
    "|66-75| Somewhat easy| 12 year-old students\n",
    "|76-85| Easy| 11 year-old students\n",
    "|86-100| Very easy| 6 to 10 year-olds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "inner-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def szigriszt_pazos_adapted(text):\n",
    "    \"\"\"Returns szigriszt-Pazos index of the articles of an author\"\"\"\n",
    "    \n",
    "    # Clean html expressions and line breaks\n",
    "    text = html_cleaner(text)\n",
    "    \n",
    "    # Get szigriszt_pazos index\n",
    "    index = szigriszt_pazos(text)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-being",
   "metadata": {},
   "source": [
    "## Usage of common words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-pregnancy",
   "metadata": {},
   "source": [
    "Higher score means the words used are more common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "colored-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stop words\n",
    "stop_words = get_stop_words('es')\n",
    "\n",
    "# Add additional stopwords\n",
    "more_stopwords = ['el', 'la', 'los', 'las', 'un', 'uno', 'una', 'unos', 'unas']\n",
    "                  \n",
    "for word in more_stopwords:\n",
    "    stop_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "inside-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency_score(text):\n",
    "    \"\"\"Returns a score of how frequent are the words used in the text\"\"\"\n",
    "    \n",
    "    # Clean html expressions, line breaks, and punctuation\n",
    "    text = html_cleaner(text)\n",
    "    text = punctuation_cleaner(text)\n",
    "    \n",
    "    # Remove Roman numerals\n",
    "    text = re.sub(r'\\b[IVXL]+\\b', '', text)\n",
    "    \n",
    "    # Lowercase all words\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Get words and remove stopwords\n",
    "    stop_words = get_stop_words('es')\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Calculate individual frequency of each word\n",
    "    words_freq = [word_frequency(word, 'es') for word in words]   \n",
    "    \n",
    "    #Sum frequencies and divide by the number of words\n",
    "    score = sum(words_freq) / len(words_freq) * 100\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-improvement",
   "metadata": {},
   "source": [
    "# Clarity metrics of all authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "civilian-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clarity = data.copy()\n",
    "data_clarity['sentence length'] = data_clarity.body.apply(avg_words_per_sentence).round(2)\n",
    "data_clarity['word length'] = data_clarity.body.apply(avg_syllables_per_word).round(2)\n",
    "data_clarity['word frequency score'] = data_clarity.body.apply(word_frequency_score).round(3)\n",
    "data_clarity['szigriszt-pazos'] = data_clarity.body.apply(szigriszt_pazos_adapted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "average-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(values, new_min=0, new_max=100):\n",
    "    \"\"\"Changes the values of a variable to another scale\"\"\"\n",
    "    \n",
    "    output = []\n",
    "    old_min, old_max = min(values), max(values)\n",
    "\n",
    "    for v in values:\n",
    "        new_v = (new_max - new_min) / (old_max - old_min) * (v - old_min) + new_min\n",
    "        output.append(new_v)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ecological-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform 'word frequency score' to a 0-100 scale for easier interpretation\n",
    "data_clarity['word frequency score'] = rescale(data_clarity['word frequency score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "capable-marsh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence length</th>\n",
       "      <th>word length</th>\n",
       "      <th>szigriszt-pazos</th>\n",
       "      <th>word frequency score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Denisse Dresser</th>\n",
       "      <td>18.61</td>\n",
       "      <td>2.05</td>\n",
       "      <td>52.09</td>\n",
       "      <td>42.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enrique Krauze</th>\n",
       "      <td>21.71</td>\n",
       "      <td>2.02</td>\n",
       "      <td>57.33</td>\n",
       "      <td>41.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John Ackerman</th>\n",
       "      <td>40.69</td>\n",
       "      <td>2.07</td>\n",
       "      <td>32.77</td>\n",
       "      <td>40.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ricardo Raphael</th>\n",
       "      <td>23.60</td>\n",
       "      <td>2.03</td>\n",
       "      <td>55.45</td>\n",
       "      <td>41.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valeria Moy</th>\n",
       "      <td>19.11</td>\n",
       "      <td>1.98</td>\n",
       "      <td>64.92</td>\n",
       "      <td>54.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sentence length  word length  szigriszt-pazos  \\\n",
       "author                                                           \n",
       "Denisse Dresser            18.61         2.05            52.09   \n",
       "Enrique Krauze             21.71         2.02            57.33   \n",
       "John Ackerman              40.69         2.07            32.77   \n",
       "Ricardo Raphael            23.60         2.03            55.45   \n",
       "Valeria Moy                19.11         1.98            64.92   \n",
       "\n",
       "                 word frequency score  \n",
       "author                                 \n",
       "Denisse Dresser                 42.89  \n",
       "Enrique Krauze                  41.68  \n",
       "John Ackerman                   40.83  \n",
       "Ricardo Raphael                 41.87  \n",
       "Valeria Moy                     54.68  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clarity.groupby('author')[['sentence length', 'word length', 'szigriszt-pazos', 'word frequency score']].mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-concern",
   "metadata": {},
   "source": [
    "# Export database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "composed-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv\n",
    "data_clarity.to_csv('../Data/Data_clean_csv/data_clarity_metrics', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
